{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projet de deep learning réalisé dans le cadre du module d'IA.\n",
    "\n",
    "### Sujet choisi : Classification d'images de chats et de chiens en utilisant un réseau neuronal convolutif\n",
    "\n",
    "#### 1 - Import des librairies nécessaires au projet\n",
    "- numpy : Utilisé pour gérer les tableaux de données\n",
    "- pandas : Utilisé pour convertir les données de résultat en csv\n",
    "- cv2 : Utilisé pour lire et traier les images\n",
    "- tensorflow : Utilisé pour créer notre réseau de neurone et l'entraîner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Récupération et pré-traitements des données\n",
    "\n",
    "Ici, on créer une fonction qui parcours toutes les images d'entraînement (dossier \"dataset/train/) et plusieurs traitements sont effectués :\n",
    "- On utilise cv2 pour lire l'image en niveau de gris et la transformer en tableau de pixels (0 à 255)\n",
    "- Redimensionne le tableau avec un taille de 80 x 80\n",
    "- Ajoute ce tableau au tableau de données d'entraînement \"X\".\n",
    "- Ajoute la catégorie réelle, chien ou chat de l'image au tableau des résultats attendus \"y\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./dataset/train/\"\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "convert = lambda category : int(category == 'dog')\n",
    "def create_test_data(train_path):\n",
    "    for p in os.listdir(train_path):\n",
    "        category = p.split(\".\")[0]\n",
    "        category = convert(category)\n",
    "        img_array = cv2.imread(os.path.join(train_path,p),cv2.IMREAD_GRAYSCALE)\n",
    "        new_img_array = cv2.resize(img_array, dsize=(80, 80))\n",
    "        X.append(new_img_array)\n",
    "        y.append(category)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Création des données d'entraînements\n",
    "Ici nous appellons la fonction défini précédemment pour créer les données d'entrainements.\n",
    "Nous donnons ensuite au tableau une forme de vecteur vertical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_test_data(train_path)\n",
    "X = np.array(X).reshape(-1, 80,80,1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - Normalisation de la valeur des pixels\n",
    "Avec des valeurs allant de 0 à 255, l'apprentissage pour notre modèle est plus difficile.\n",
    "C'est pourquoi nous normalisons ces valeurs afin de les ramener entre 0 et 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 - Création du modèle\n",
    "Nous créons un modèle séquentiel à deux couches avec les caractéristiques suivantes :\n",
    "- 64 filtres\n",
    "- Un motif de taille (3,3) --> motif de kernel\n",
    "- Une fonction d'activation relu permettant de remplacer les résultats négatifs par 0\n",
    "\n",
    "Ces deux couches sont entièrement connectées, c'est-à-dire que chaque neurone est relié à chaque neurone de la couche précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Adds a densely-connectpathed layer with 64 units to the model:\n",
    "model.add(Conv2D(64,(3,3), activation = 'relu', input_shape = X.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "# Add another:\n",
    "model.add(Conv2D(64,(3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 - Entraînment du modèle\n",
    "- Nous avons choisi d'entraîner notre modèle sur 10 époques. Cet à dire qu'on passe toutes les images d'entraînements 10 fois.\n",
    "- On décide de passer 32 images par 32 pour réaliser une époque.\n",
    "- On décide de prendre les derniers 20% des images d'entraînements pour tester notre modèle sur l'époque actuelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7 - Interprétation des résultats\n",
    "\n",
    "Une fois le modèle entraîné, nous le testons avec les images de tests qui n'ont pas été donné auparavant.\n",
    "Nous arrondissons les valeurs pour soit obtenir 1 (chien) ou 0 (chat).\n",
    "Enfin, nous mettons les résultats dans un DataFrame pandas qui sera exporté en csv pour mieux visualiser les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predicted_val = [int(round(p[0])) for p in predictions]\n",
    "submission_df = pd.DataFrame({'id':id_line, 'label':predicted_val})\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
